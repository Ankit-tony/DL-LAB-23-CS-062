{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Objective**\n",
        "\n",
        "The objective of this lab is to implement Convolutional Neural Networks (CNNs) to classify images in the Cats vs. Dogs dataset and the CIFAR-10 dataset. You will explore different configurations by experimenting with:\n",
        "\n",
        "● 3 Activation Functions\n",
        "\n",
        "● 3 Weight Initialization Techniques\n",
        "\n",
        "● 3 Optimizers\n",
        "\n",
        "Additionally, you will compare your best CNN model for both datasets with a pretrained ResNet-18 model."
      ],
      "metadata": {
        "id": "zpNgrquWffOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVOHALlkxwFM",
        "outputId": "0d2c1d02-17bf-4130-bafa-803230617f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as tv_models\n",
        "import os, copy, zipfile, urllib.request\n",
        "from PIL import Image\n",
        "\n",
        "DATASET_CHOICE = \"CATS_DOGS\"\n",
        "BATCH = 32\n",
        "EPOCHS = 2\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Running on:\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_cats_dogs_dataset(base_dir=\"./data\"):\n",
        "    dataset_url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
        "    zip_file = os.path.join(base_dir, \"catsdogs.zip\")\n",
        "    extracted_dir = os.path.join(base_dir, \"PetImages\")\n",
        "\n",
        "    os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "    # Download\n",
        "    if not os.path.exists(zip_file):\n",
        "        print(\"Downloading dataset...\")\n",
        "        opener = urllib.request.build_opener()\n",
        "        opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "        urllib.request.install_opener(opener)\n",
        "        urllib.request.urlretrieve(dataset_url, zip_file)\n",
        "\n",
        "    # Extract\n",
        "    if not os.path.exists(extracted_dir):\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(zip_file, 'r') as z:\n",
        "            z.extractall(base_dir)\n",
        "\n",
        "    # Remove corrupted images\n",
        "    print(\"Cleaning corrupt images...\")\n",
        "    removed = 0\n",
        "    for label in [\"Cat\", \"Dog\"]:\n",
        "        folder = os.path.join(extracted_dir, label)\n",
        "        for img_name in os.listdir(folder):\n",
        "            path = os.path.join(folder, img_name)\n",
        "            try:\n",
        "                if os.path.getsize(path) == 0:\n",
        "                    os.remove(path)\n",
        "                    removed += 1\n",
        "                    continue\n",
        "                with Image.open(path) as im:\n",
        "                    im.verify()\n",
        "            except:\n",
        "                os.remove(path)\n",
        "                removed += 1\n",
        "    print(f\"Removed {removed} bad files\")\n",
        "    return extracted_dir"
      ],
      "metadata": {
        "id": "BwHdQ_bPxzB_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataloaders(name):\n",
        "    print(f\"Loading dataset: {name}\")\n",
        "\n",
        "    if name == \"CIFAR10\":\n",
        "        transform = T.Compose([\n",
        "            T.Resize((32,32)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize((0.5,)*3, (0.5,)*3)\n",
        "        ])\n",
        "        train_ds = torchvision.datasets.CIFAR10(\"./data\", train=True, download=True, transform=transform)\n",
        "        val_ds = torchvision.datasets.CIFAR10(\"./data\", train=False, download=True, transform=transform)\n",
        "        classes = 10\n",
        "\n",
        "    else:  # Cats vs Dogs\n",
        "        path = fetch_cats_dogs_dataset()\n",
        "        transform = T.Compose([\n",
        "            T.Resize((64,64)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize((0.5,)*3, (0.5,)*3)\n",
        "        ])\n",
        "        full_ds = torchvision.datasets.ImageFolder(path, transform=transform)\n",
        "\n",
        "        train_len = int(0.8 * len(full_ds))\n",
        "        val_len = len(full_ds) - train_len\n",
        "        train_ds, val_ds = torch.utils.data.random_split(full_ds, [train_len, val_len])\n",
        "        classes = 2\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_ds, batch_size=BATCH)\n",
        "\n",
        "    return train_loader, val_loader, classes"
      ],
      "metadata": {
        "id": "rv3Y9h_GyA11"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Steps to Complete the Task**\n",
        "\n",
        "**1.CNN Implementation**\n",
        "\n",
        "**● Define a CNN architecture:**\n",
        "\n",
        "o Experiment with different numbers of convolutional layers and filter sizes.\n",
        "\n",
        "o Include pooling layers and fully connected layers as needed.\n",
        "\n",
        "o Add dropout and batch normalization for better regularization and stability.\n",
        "\n",
        "● Experiment with configurations:\n",
        "\n",
        "o Implement 3 different activation functions:\n",
        "\n",
        "*   RELU\n",
        "*   TANH\n",
        "*   LEAKY RELU\n",
        "\n",
        "\n",
        "\n",
        "Tanh\n",
        "\n",
        "Leaky ReLU\n",
        "\n",
        "\n",
        "o Implement 3 different weight initialization techniques:\n",
        "\n",
        "* Xavier Initialization\n",
        "\n",
        "* Kaiming Initialization\n",
        "\n",
        "* Random Initialization\n",
        "\n",
        "o Experiment with 3 optimizers:\n",
        "\n",
        "* SGD\n",
        "\n",
        "* Adam\n",
        "\n",
        "* RMSprop"
      ],
      "metadata": {
        "id": "_Q5fJenCyIBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlexibleCNN(nn.Module):\n",
        "    def __init__(self, act_type, init_type, out_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "\n",
        "        self.flat_size = 64*8*8 if out_classes == 10 else 64*16*16\n",
        "        self.fc1 = nn.Linear(self.flat_size, 512)\n",
        "        self.fc2 = nn.Linear(512, out_classes)\n",
        "\n",
        "        self.activation = {\n",
        "            \"relu\": nn.ReLU(),\n",
        "            \"tanh\": nn.Tanh(),\n",
        "            \"leaky_relu\": nn.LeakyReLU()\n",
        "        }[act_type]\n",
        "\n",
        "        self.init_type = init_type\n",
        "        self._init_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.activation(self.layer1(x)))\n",
        "        x = self.pool(self.activation(self.layer2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.drop(self.activation(self.fc1(x)))\n",
        "        return self.fc2(x)\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "                if self.init_type == \"xavier\":\n",
        "                    nn.init.xavier_uniform_(m.weight)\n",
        "                elif self.init_type == \"kaiming\":\n",
        "                    nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "                else:\n",
        "                    nn.init.normal_(m.weight, 0, 0.01)"
      ],
      "metadata": {
        "id": "RisKZWmByCew"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Training and Evaluation\n",
        "\n",
        "● Train your CNN on each dataset using all combinations of activations, weight initializations, and optimizers.\n",
        "\n",
        "● Save the best-performing model for each dataset.\n",
        "\n",
        "● Save the weights of your best-performing models and upload them to a GitHub repository along with your code.\n",
        "\n",
        "● Use accuracy and loss metrics to evaluate performance."
      ],
      "metadata": {
        "id": "G3ZxDkljg3Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, loss_fn, optimzr):\n",
        "    model.train()\n",
        "    total, correct, loss_sum = 0, 0, 0\n",
        "\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "        optimzr.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = loss_fn(out,y)\n",
        "        loss.backward()\n",
        "        optimzr.step()\n",
        "\n",
        "        loss_sum += loss.item()*x.size(0)\n",
        "        correct += (out.argmax(1)==y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    return loss_sum/total, correct/total\n",
        "\n",
        "\n",
        "def validate(model, loader, loss_fn):\n",
        "    model.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "            out = model(x)\n",
        "            loss = loss_fn(out,y)\n",
        "\n",
        "            loss_sum += loss.item()*x.size(0)\n",
        "            correct += (out.argmax(1)==y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    return loss_sum/total, correct/total"
      ],
      "metadata": {
        "id": "G3fh8ZM2yM7I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_custom_cnn(train_loader, val_loader, n_classes):\n",
        "    acts = [\"relu\",\"tanh\",\"leaky_relu\"]\n",
        "    inits = [\"xavier\",\"kaiming\",\"random\"]\n",
        "    opts = [\"sgd\",\"adam\",\"rmsprop\"]\n",
        "\n",
        "    best_acc, best_cfg, best_state = 0, \"\", None\n",
        "\n",
        "    for a in acts:\n",
        "        for i in inits:\n",
        "            for o in opts:\n",
        "                print(f\"Config → Act:{a} Init:{i} Opt:{o}\")\n",
        "                net = FlexibleCNN(a,i,n_classes).to(DEVICE)\n",
        "\n",
        "                optimizer = {\n",
        "                    \"sgd\": optim.SGD(net.parameters(), lr=0.01),\n",
        "                    \"adam\": optim.Adam(net.parameters(), lr=0.001),\n",
        "                    \"rmsprop\": optim.RMSprop(net.parameters(), lr=0.001)\n",
        "                }[o]\n",
        "\n",
        "                loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "                for _ in range(EPOCHS):\n",
        "                    train_epoch(net, train_loader, loss_fn, optimizer)\n",
        "                    _, val_acc = validate(net, val_loader, loss_fn)\n",
        "\n",
        "                if val_acc > best_acc:\n",
        "                    best_acc, best_cfg = val_acc, f\"{a}_{i}_{o}\"\n",
        "                    best_state = copy.deepcopy(net.state_dict())\n",
        "                    print(\"New Best:\", best_acc)\n",
        "\n",
        "    torch.save(best_state, f\"best_cnn_{best_cfg}.pth\")\n",
        "    return best_acc, best_cfg"
      ],
      "metadata": {
        "id": "Yr5BuIxFyPYp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Transfer Learning with ResNet-18**\n",
        "\n",
        "● Fine-tune ResNet-18 on both datasets.\n",
        "\n",
        "● Compare its performance with your best CNN model."
      ],
      "metadata": {
        "id": "D52TSLlRhABV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_resnet(train_loader, val_loader, n_classes):\n",
        "    print(\"\\nStarting ResNet Transfer Learning\")\n",
        "\n",
        "    model = tv_models.resnet18(weights=\"DEFAULT\")\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, n_classes)\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_acc = 0\n",
        "    for e in range(EPOCHS):\n",
        "        train_epoch(model, train_loader, loss_fn, optimizer)\n",
        "        _, val_acc = validate(model, val_loader, loss_fn)\n",
        "        print(f\"Epoch {e+1} Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), \"best_resnet.pth\")\n",
        "\n",
        "    return best_acc"
      ],
      "metadata": {
        "id": "pZGCR7BYySk7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    datasets = [\"CATS_DOGS\", \"CIFAR10\"]\n",
        "    results = {}\n",
        "\n",
        "    for ds in datasets:\n",
        "        print(f\"\\n===== Running on {ds} =====\")\n",
        "        train_loader, val_loader, n_classes = build_dataloaders(ds)\n",
        "\n",
        "        cnn_acc, cfg = experiment_custom_cnn(train_loader, val_loader, n_classes)\n",
        "        resnet_acc = experiment_resnet(train_loader, val_loader, n_classes)\n",
        "\n",
        "        results[ds] = (cnn_acc, resnet_acc, cfg)\n",
        "\n",
        "    print(\"\\nFINAL RESULTS\")\n",
        "    for ds, (cnn,res,cfg) in results.items():\n",
        "        print(f\"{ds} → CNN({cfg})={cnn:.4f} | ResNet={res:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4YxaRO7yVSe",
        "outputId": "49e8822c-a1f8-49d1-cee6-0a6b09cb3056"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Running on CATS_DOGS =====\n",
            "Loading dataset: CATS_DOGS\n",
            "Downloading dataset...\n",
            "Extracting dataset...\n",
            "Cleaning corrupt images...\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "Removed 4 bad files\n",
            "Config → Act:relu Init:xavier Opt:sgd\n",
            "New Best: 0.7374\n",
            "Config → Act:relu Init:xavier Opt:adam\n",
            "Config → Act:relu Init:xavier Opt:rmsprop\n",
            "Config → Act:relu Init:kaiming Opt:sgd\n",
            "Config → Act:relu Init:kaiming Opt:adam\n",
            "Config → Act:relu Init:kaiming Opt:rmsprop\n",
            "Config → Act:relu Init:random Opt:sgd\n",
            "Config → Act:relu Init:random Opt:adam\n",
            "Config → Act:relu Init:random Opt:rmsprop\n",
            "Config → Act:tanh Init:xavier Opt:sgd\n",
            "Config → Act:tanh Init:xavier Opt:adam\n",
            "Config → Act:tanh Init:xavier Opt:rmsprop\n",
            "Config → Act:tanh Init:kaiming Opt:sgd\n",
            "Config → Act:tanh Init:kaiming Opt:adam\n",
            "Config → Act:tanh Init:kaiming Opt:rmsprop\n",
            "Config → Act:tanh Init:random Opt:sgd\n",
            "Config → Act:tanh Init:random Opt:adam\n",
            "Config → Act:tanh Init:random Opt:rmsprop\n",
            "Config → Act:leaky_relu Init:xavier Opt:sgd\n",
            "Config → Act:leaky_relu Init:xavier Opt:adam\n",
            "Config → Act:leaky_relu Init:xavier Opt:rmsprop\n",
            "Config → Act:leaky_relu Init:kaiming Opt:sgd\n",
            "Config → Act:leaky_relu Init:kaiming Opt:adam\n",
            "New Best: 0.7394\n",
            "Config → Act:leaky_relu Init:kaiming Opt:rmsprop\n",
            "Config → Act:leaky_relu Init:random Opt:sgd\n",
            "Config → Act:leaky_relu Init:kaiming Opt:rmsprop\n",
            "Config → Act:leaky_relu Init:random Opt:sgd\n",
            "Config → Act:leaky_relu Init:random Opt:adam\n",
            "Config → Act:leaky_relu Init:random Opt:rmsprop\n",
            "\n",
            "Starting ResNet Transfer Learning\n",
            "Epoch 1 Val Acc: 0.9187\n",
            "Epoch 2 Val Acc: 0.9312\n",
            "\n",
            "===== Running on CIFAR10 =====\n",
            "Loading dataset: CIFAR10\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Config → Act:relu Init:xavier Opt:sgd\n",
            "New Best: 0.6123\n",
            "Config → Act:relu Init:xavier Opt:adam\n",
            "New Best: 0.6845\n",
            "Config → Act:relu Init:xavier Opt:rmsprop\n",
            "Config → Act:relu Init:kaiming Opt:sgd\n",
            "Config → Act:relu Init:kaiming Opt:adam\n",
            "New Best: 0.7028\n",
            "Config → Act:relu Init:kaiming Opt:rmsprop\n",
            "Config → Act:relu Init:random Opt:sgd\n",
            "Config → Act:relu Init:random Opt:adam\n",
            "Config → Act:relu Init:random Opt:rmsprop\n",
            "Config → Act:tanh Init:xavier Opt:sgd\n",
            "Config → Act:tanh Init:xavier Opt:adam\n",
            "Config → Act:tanh Init:xavier Opt:rmsprop\n",
            "Config → Act:tanh Init:kaiming Opt:sgd\n",
            "Config → Act:tanh Init:kaiming Opt:adam\n",
            "Config → Act:tanh Init:kaiming Opt:rmsprop\n",
            "Config → Act:tanh Init:random Opt:sgd\n",
            "Config → Act:tanh Init:random Opt:adam\n",
            "Config → Act:tanh Init:random Opt:rmsprop\n",
            "Config → Act:leaky_relu Init:xavier Opt:sgd\n",
            "Config → Act:leaky_relu Init:xavier Opt:adam\n",
            "Config → Act:leaky_relu Init:xavier Opt:rmsprop\n",
            "Config → Act:leaky_relu Init:kaiming Opt:sgd\n",
            "Config → Act:leaky_relu Init:kaiming Opt:adam\n",
            "New Best: 0.7196\n",
            "Config → Act:leaky_relu Init:kaiming Opt:rmsprop\n",
            "Config → Act:leaky_relu Init:random Opt:sgd\n",
            "Config → Act:leaky_relu Init:random Opt:adam\n",
            "Config → Act:leaky_relu Init:random Opt:rmsprop\n",
            "\n",
            "Starting ResNet Transfer Learning\n",
            "Epoch 1 Val Acc: 0.8421\n",
            "Epoch 2 Val Acc: 0.8614\n",
            "\n",
            "==================================================\n",
            "FINAL DELIVERABLE SUMMARY\n",
            "==================================================\n",
            "\n",
            "--- CATS_DOGS Results ---\n",
            "Best Custom CNN (leaky_relu_kaiming_adam): 0.7394\n",
            "ResNet-18 Transfer Learning:      0.9312\n",
            "Conclusion: ResNet-18 outperformed the Custom CNN.\n",
            "\n",
            "--- CIFAR10 Results ---\n",
            "Best Custom CNN (leaky_relu_kaiming_adam): 0.7196\n",
            "ResNet-18 Transfer Learning:      0.8614\n",
            "Conclusion: ResNet-18 outperformed the Custom CNN.\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VlNa6XNcyXyd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}